import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import joblib
import os
from datetime import datetime, timedelta
from threading import Thread
import time
import random
from collections import deque
import json

from data.collector import UpbitDataCollector
from models.feature_engineering import FeatureEngineer
from strategy.base import BaseStrategy
from utils.logger import setup_logger
from config.settings import MODEL_DIR

logger = setup_logger("market_state_detector")

class MarketState:
    """ì‹œì¥ ìƒíƒœ ì •ë³´"""
    
    def __init__(self, state_id, features=None, characteristics=None):
        """ì´ˆê¸°í™”"""
        self.state_id = state_id
        self.features = features or {}
        self.characteristics = characteristics or {}
        self.occurrences = 1
        self.last_seen = datetime.now()
        self.optimal_strategy = None
        
        # ğŸ”§ ì´ ë¶€ë¶„ì„ ì™„ì „íˆ ì œê±°í•˜ê±°ë‚˜ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”
        """
        # ê°ì§€ ë°©ë²• ê²€ì¦ ë° ì„¤ì • - ì´ ë¶€ë¶„ì´ ë¬¸ì œ!
        valid_methods = ['clustering', 'hmm', 'cusum']
        if detection_method not in valid_methods:  # detection_methodê°€ ì—†ìŒ!
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ê°ì§€ ë°©ë²•: {detection_method}, clusteringìœ¼ë¡œ ì„¤ì •")
            detection_method = 'clustering'
        """
        
    def update(self, features=None, characteristics=None):
        """ìƒíƒœ ì •ë³´ ì—…ë°ì´íŠ¸"""
        if features:
            self.features = features
            
        if characteristics:
            self.characteristics = characteristics
            
        self.last_seen = datetime.now()
        self.occurrences += 1
        
    def get_state_summary(self):
        """ìƒíƒœ ìš”ì•½ ì •ë³´"""
        summary = {
            'state_id': self.state_id,
            'characteristics': self.characteristics,
            'occurrences': self.occurrences,
            'last_seen': self.last_seen,
            'optimal_strategy': self.optimal_strategy
        }
        return summary
    
    def __str__(self):
        """ë¬¸ìì—´ í‘œí˜„"""
        chars = []
        for key, value in self.characteristics.items():
            if isinstance(value, float):
                chars.append(f"{key}: {value:.2f}")
            else:
                chars.append(f"{key}: {value}")
                
        return f"ìƒíƒœ {self.state_id}: {', '.join(chars)}, ë°œìƒ {self.occurrences}íšŒ"

class MarketStateDetector:
    """ì‹œì¥ ìƒíƒœ ê°ì§€ ëª¨ë“ˆ"""
    
    def __init__(self, ticker="KRW-BTC", detection_method='clustering', n_states=5):
        """ì´ˆê¸°í™”"""
        self.ticker = ticker
        self.n_states = n_states  # êµ°ì§‘ ë˜ëŠ” ìƒíƒœ ìˆ˜
        
        # ğŸ”§ ê°ì§€ ë°©ë²• ê²€ì¦ì„ ì—¬ê¸°ì„œ í•´ì•¼ í•¨ (MarketStateê°€ ì•„ë‹ˆë¼)
        valid_methods = ['clustering', 'hmm', 'cusum']
        if detection_method not in valid_methods:
            logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ê°ì§€ ë°©ë²•: {detection_method}, clusteringìœ¼ë¡œ ì„¤ì •")
            detection_method = 'clustering'
        
        self.detection_method = detection_method
        
        # ë°ì´í„° ìˆ˜ì§‘ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
        self.collector = UpbitDataCollector()
        self.fe = FeatureEngineer()
        
        # ë°ì´í„° ìˆ˜ì§‘ ì£¼ê¸°
        self.data_timeframe = 'day'  # 'day', 'hour', 'minute30'
        self.data_count = 60  # ìµœê·¼ 60ê°œ ë°ì´í„°
        
        # ëª¨ë¸ ë° ìƒíƒœ ì •ë³´
        self.model = None  # êµ°ì§‘ ë˜ëŠ” HMM ëª¨ë¸
        self.scaler = StandardScaler()  # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        self.market_states = {}  # ìƒíƒœ ID -> MarketState ê°ì²´
        self.current_state = None  # í˜„ì¬ ì‹œì¥ ìƒíƒœ
        self.previous_state_id = None  # ì´ ì¤„ ì¶”ê°€
        self.state_history = deque(maxlen=100)  # ìµœê·¼ 100ê°œ ìƒíƒœ ê¸°ë¡
        
        # ìƒíƒœ í‰ê°€ ì§€í‘œ
        self.state_metrics = {}  # ìƒíƒœ ID -> {ì „ëµ -> ìˆ˜ìµë¥  í†µê³„}
        
        # CUSUM ë³€ìˆ˜
        self.cusum_threshold = 1.0  # ë³€í™” ê°ì§€ ì„ê³„ê°’
        self.cusum_pos = 0  # ì–‘ì˜ ëˆ„ì í•©
        self.cusum_neg = 0  # ìŒì˜ ëˆ„ì í•©
        self.cusum_baseline = None  # ê¸°ì¤€ê°’
        
        # ìë™ ì‹¤í–‰
        self.running = False
        self.update_interval = 3600  # 1ì‹œê°„ë§ˆë‹¤ ì—…ë°ì´íŠ¸
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.save_dir = os.path.join(MODEL_DIR, "market_states")
        os.makedirs(self.save_dir, exist_ok=True)
        
    def collect_data(self):
        """ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘"""
        if self.data_timeframe == 'day':
            df = self.collector.get_ohlcv(self.ticker, interval="day", count=self.data_count)
        elif self.data_timeframe == 'hour':
            df = self.collector.get_ohlcv(self.ticker, interval="minute60", count=self.data_count)
        elif self.data_timeframe == 'minute30':
            df = self.collector.get_ohlcv(self.ticker, interval="minute30", count=self.data_count)
        else:
            logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œê°„í”„ë ˆì„: {self.data_timeframe}")
            return None
            
        if df is None or len(df) < self.data_count * 0.8:
            logger.error(f"ë°ì´í„° ë¶€ì¡±: {len(df) if df is not None else 0} í–‰")
            return None
            
        # íŠ¹ì„± ì¶”ê°€
        df = self.fe.add_indicators(df)
        
        logger.debug(f"ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df)} í–‰")
        return df
    
    def extract_features(self, df):
        """ì‹œì¥ íŠ¹ì„± ì¶”ì¶œ"""
        if df is None or len(df) < 5:  # ìµœì†Œ 5ê°œ ë°ì´í„° í•„ìš”
            return None
            
        features = {}
        
        # 1. ì¶”ì„¸ íŠ¹ì„±
        features['trend_direction'] = 1 if df['close'].iloc[-1] > df['ma20'].iloc[-1] else -1
        features['trend_strength'] = abs(df['close'].iloc[-1] / df['ma20'].iloc[-1] - 1)
        
        # 2. ë³€ë™ì„± íŠ¹ì„±
        features['volatility'] = df['close'].pct_change().std() * np.sqrt(252)  # ì—°ê°„í™”
        features['daily_range'] = ((df['high'] - df['low']) / df['low']).mean() * 100
        
        # 3. ëª¨ë©˜í…€ íŠ¹ì„±
        features['rsi'] = df['rsi'].iloc[-1]
        features['macd_hist'] = df['macd_hist'].iloc[-1]
        
        # 4. ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜
        if 'bb_position' in df.columns:
            features['bb_position'] = df['bb_position'].iloc[-1]
        else:
            bb_upper = df['bb_upper'].iloc[-1]
            bb_lower = df['bb_lower'].iloc[-1]
            close = df['close'].iloc[-1]
            features['bb_position'] = (close - bb_lower) / (bb_upper - bb_lower)
        
        # 5. ê±°ë˜ëŸ‰ íŠ¹ì„±
        features['volume_ratio'] = df['volume'].iloc[-5:].mean() / df['volume'].iloc[:-5].mean()
        
        return features
    
    def characterize_market_state(self, features):
        """ì‹œì¥ ìƒíƒœ íŠ¹ì„±í™”"""
        if features is None:
            return None
            
        characteristics = {}
        
        # ì¶”ì„¸ ë°©í–¥ ë° ê°•ë„
        if features['trend_direction'] > 0:
            if features['trend_strength'] > 0.05:
                characteristics['trend'] = "ê°•í•œ ìƒìŠ¹"
            else:
                characteristics['trend'] = "ì•½í•œ ìƒìŠ¹"
        else:
            if features['trend_strength'] > 0.05:
                characteristics['trend'] = "ê°•í•œ í•˜ë½"
            else:
                characteristics['trend'] = "ì•½í•œ í•˜ë½"
                
        # ë³€ë™ì„±
        if features['volatility'] > 0.8:
            characteristics['volatility'] = "ë§¤ìš° ë†’ìŒ"
        elif features['volatility'] > 0.5:
            characteristics['volatility'] = "ë†’ìŒ"
        elif features['volatility'] > 0.3:
            characteristics['volatility'] = "ë³´í†µ"
        else:
            characteristics['volatility'] = "ë‚®ìŒ"
            
        # ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„
        if features['rsi'] > 70:
            characteristics['momentum'] = "ê³¼ë§¤ìˆ˜"
        elif features['rsi'] < 30:
            characteristics['momentum'] = "ê³¼ë§¤ë„"
        else:
            characteristics['momentum'] = "ì¤‘ë¦½"
            
        # ê±°ë˜ëŸ‰
        if features['volume_ratio'] > 1.5:
            characteristics['volume'] = "ê¸‰ì¦"
        elif features['volume_ratio'] < 0.7:
            characteristics['volume'] = "ê¸‰ê°"
        else:
            characteristics['volume'] = "ë³´í†µ"
            
        return characteristics
    
    def detect_state_clustering(self, df):
        """êµ°ì§‘í™” ê¸°ë°˜ ì‹œì¥ ìƒíƒœ ê°ì§€"""
        if df is None or len(df) < 10:
            logger.error("êµ°ì§‘í™”ë¥¼ ìœ„í•œ ë°ì´í„° ë¶€ì¡±")
            return self._create_default_state()
            
        # êµ°ì§‘í™”ì— ì‚¬ìš©í•  í•„ìˆ˜ íŠ¹ì„± í™•ì¸ ë° ìƒì„±
        required_features = ['ma_ratio_5_20', 'rsi', 'bb_width', 'macd_hist', 'volume_ratio']
        
        # íŠ¹ì„± ì¶”ê°€ í•„ìš” ì—¬ë¶€ í™•ì¸
        need_features = False
        for feature in required_features:
            if feature not in df.columns:
                need_features = True
                break
                
        # íŠ¹ì„± ì¶”ê°€ê°€ í•„ìš”í•œ ê²½ìš°
        if need_features:
            try:
                from models.feature_engineering import FeatureEngineer
                fe = FeatureEngineer()
                
                # ê¸°ë³¸ ì§€í‘œ í™•ì¸
                if not all(col in df.columns for col in ['ma5', 'ma20', 'volume']):
                    logger.warning("ê¸°ë³¸ ê¸°ìˆ ì  ì§€í‘œ ëˆ„ë½, ì¶”ê°€ ì‹œë„")
                    df = fe.add_indicators(df)
                
                # ML íŠ¹ì„± ì¶”ê°€ ì‹œë„
                df = fe.add_ml_features(df)
                
                # í•„ìˆ˜ íŠ¹ì„± ì§ì ‘ ê³„ì‚° (add_ml_features ì‹¤íŒ¨ ì‹œ)
                if 'ma_ratio_5_20' not in df.columns and 'ma5' in df.columns and 'ma20' in df.columns:
                    df['ma_ratio_5_20'] = df['ma5'] / df['ma20']
                    
                if 'volume_ratio' not in df.columns and 'volume' in df.columns:
                    df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()
                    
                if 'bb_width' not in df.columns and 'bb_upper' in df.columns and 'bb_lower' in df.columns:
                    df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle'] if 'bb_middle' in df.columns else 0
                    
            except Exception as e:
                logger.error(f"íŠ¹ì„± ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
                return self._create_default_state()
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„± í™•ì¸
        available_features = [f for f in required_features if f in df.columns]
        
        # ìµœì†Œ 2ê°œ ì´ìƒì˜ íŠ¹ì„±ì´ ìˆì–´ì•¼ í•¨
        if len(available_features) < 2:
            logger.error(f"êµ°ì§‘í™”ì— í•„ìš”í•œ íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í•„ìš”: {required_features}, ê°€ìš©: {available_features}")
            return self._create_default_state()
            
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±ë§Œ ì„ íƒ
            features = df[available_features].dropna()
                
            # ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ë¡œë“œ
            if self.model is None:
                # ìµœê·¼ì— ì €ì¥ëœ ëª¨ë¸ í™•ì¸
                model_path = os.path.join(self.save_dir, f"{self.ticker}_kmeans_{self.n_states}.joblib")
                if os.path.exists(model_path):
                    try:
                        # ëª¨ë¸ ë¡œë“œ
                        model_data = joblib.load(model_path)
                        self.model = model_data['model']
                        self.scaler = model_data['scaler']
                        self.market_states = model_data.get('market_states', {})
                        logger.info(f"êµ°ì§‘í™” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
                    except Exception as e:
                        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                        self.model = None
                
                # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµ
                if self.model is None:
                    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
                    self.scaler = StandardScaler()
                    scaled_features = self.scaler.fit_transform(features)
                    
                    # KMeans êµ°ì§‘í™”
                    from sklearn.cluster import KMeans
                    self.model = KMeans(n_clusters=self.n_states, random_state=42)
                    self.model.fit(scaled_features)
                    
                    logger.info(f"ìƒˆ êµ°ì§‘í™” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {self.n_states}ê°œ êµ°ì§‘")
            
            # í˜„ì¬ ìƒíƒœ ì˜ˆì¸¡
            if len(features) > 0:
                current_features = features.iloc[-1:].values.reshape(1, -1)
                scaled_current = self.scaler.transform(current_features)
                state_id = int(self.model.predict(scaled_current)[0])
                
                # íŠ¹ì„± í‰ê·  ê³„ì‚° (í•´ë‹¹ êµ°ì§‘ì˜ íŠ¹ì„±)
                if state_id in self.market_states:
                    # ê¸°ì¡´ ìƒíƒœ ì—…ë°ì´íŠ¸
                    state = self.market_states[state_id]
                    features_dict = self.extract_features(df)
                    characteristics = self.characterize_market_state(features_dict)
                    state.update(features_dict, characteristics)
                else:
                    # ìƒˆ ìƒíƒœ ìƒì„±
                    cluster_indices = (self.model.labels_ == state_id)
                    if any(cluster_indices):
                        # í•´ë‹¹ êµ°ì§‘ ë°ì´í„°ì˜ í‰ê·  íŠ¹ì„± ê³„ì‚°
                        cluster_avg = features.iloc[cluster_indices].mean().to_dict()
                        
                        # íŠ¹ì„± ì¶”ì¶œ ë° ìƒíƒœ íŠ¹ì„±í™”
                        features_dict = self.extract_features(df)
                        characteristics = self.characterize_market_state(features_dict)
                        
                        # ìƒˆ ìƒíƒœ ê°ì²´ ìƒì„±
                        state = MarketState(state_id, features_dict, characteristics)
                        self.market_states[state_id] = state
                        
                        logger.info(f"ìƒˆ ì‹œì¥ ìƒíƒœ ê°ì§€: {state}")
                    else:
                        logger.warning(f"êµ°ì§‘ {state_id}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                        return self._create_default_state()
                
                # ìƒíƒœ ê¸°ë¡
                self.state_history.append(state_id)
                self.current_state = state
                
                # ëª¨ë¸ ì €ì¥
                self._save_model()
                
                return state
            else:
                logger.warning("ìœ íš¨í•œ íŠ¹ì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return self._create_default_state()
                
        except Exception as e:
            logger.error(f"ìƒíƒœ ê°ì§€ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return self._create_default_state()
                

    
    def _create_default_state(self):
        """ê¸°ë³¸ ì‹œì¥ ìƒíƒœ ìƒì„± (ì•ˆì „í•œ fallback)"""
        state_id = "default"
        features = {
            'trend_direction': 1,
            'trend_strength': 0.01,
            'volatility': 0.5,
            'rsi': 50,
            'volume_ratio': 1.0
        }
        characteristics = {
            "trend": "ì¤‘ë¦½",
            "volatility": "ë³´í†µ",
            "momentum": "ì¤‘ë¦½",
            "volume": "ë³´í†µ"
        }
        default_state = MarketState(state_id, features, characteristics)
        self.market_states[state_id] = default_state
        self.current_state = default_state
        logger.info("ê¸°ë³¸ ì‹œì¥ ìƒíƒœ ìƒì„±ë¨")
        return default_state
    
    def detect_state_hmm(self, df):
        """ì€ë‹‰ ë§ˆë¥´ì½”í”„ ëª¨ë¸ ê¸°ë°˜ ì‹œì¥ ìƒíƒœ ê°ì§€ (ì•ˆì „í•œ ëŒ€ì•ˆ êµ¬í˜„)"""
        if df is None or len(df) < 20:
            logger.error("HMMì„ ìœ„í•œ ë°ì´í„° ë¶€ì¡±")
            return self._create_default_state()
            
        # hmmlearn ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ìš©ì„± í™•ì¸
        try:
            from hmmlearn import hmm
            hmmlearn_available = True
            logger.debug("hmmlearn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥")
        except ImportError as e:
            logger.warning(f"hmmlearn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ: {e}")
            logger.info("Clustering ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´ ì‹¤í–‰")
            hmmlearn_available = False
        except Exception as e:
            logger.error(f"hmmlearn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜: {e}")
            logger.info("Clustering ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´ ì‹¤í–‰")
            hmmlearn_available = False
        
        # hmmlearnì´ ì—†ìœ¼ë©´ clusteringìœ¼ë¡œ ëŒ€ì²´
        if not hmmlearn_available:
            logger.info("HMM ëŒ€ì‹  í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²• ì‚¬ìš©")
            return self.detect_state_clustering(df)
        
        try:
            # HMMì— ì‚¬ìš©í•  íŠ¹ì„± ì„ íƒ
            required_features = ['rsi', 'bb_width', 'macd_hist', 'volume_ratio']
            available_features = [f for f in required_features if f in df.columns]
            
            if len(available_features) < 2:
                logger.warning("HMMìš© íŠ¹ì„± ë¶€ì¡±, í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ëŒ€ì²´")
                return self.detect_state_clustering(df)
                
            features = df[available_features].dropna()
            if len(features) < 20:
                logger.error("ìœ íš¨í•œ íŠ¹ì„± ë°ì´í„° ë¶€ì¡±")
                return self.detect_state_clustering(df)
                
            # ìŠ¤ì¼€ì¼ë§
            if not hasattr(self, 'scaler') or self.scaler is None:
                from sklearn.preprocessing import StandardScaler
                self.scaler = StandardScaler()
                
            scaled_features = self.scaler.fit_transform(features)
            
            # HMM ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ë¡œë“œ
            if self.model is None:
                model_path = os.path.join(self.save_dir, f"{self.ticker}_hmm_{self.n_states}.joblib")
                if os.path.exists(model_path):
                    try:
                        # ëª¨ë¸ ë¡œë“œ
                        model_data = joblib.load(model_path)
                        self.model = model_data['model']
                        self.scaler = model_data['scaler']
                        self.market_states = model_data.get('market_states', {})
                        logger.info(f"HMM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
                    except Exception as e:
                        logger.error(f"HMM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                        self.model = None
                        
                # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµ
                if self.model is None:
                    try:
                        # HMM ëª¨ë¸ í•™ìŠµ
                        self.model = hmm.GaussianHMM(
                            n_components=self.n_states, 
                            covariance_type="full", 
                            random_state=42,
                            n_iter=100  # ë°˜ë³µ íšŸìˆ˜ ì œí•œ
                        )
                        self.model.fit(scaled_features)
                        logger.info(f"ìƒˆ HMM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {self.n_states}ê°œ ìƒíƒœ")
                    except Exception as e:
                        logger.error(f"HMM ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
                        logger.info("í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´")
                        return self.detect_state_clustering(df)
            
            # í˜„ì¬ ìƒíƒœ ì˜ˆì¸¡
            try:
                predicted_states = self.model.predict(scaled_features)
                current_state_id = int(predicted_states[-1])
            except Exception as e:
                logger.error(f"HMM ìƒíƒœ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                logger.info("í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´")
                return self.detect_state_clustering(df)
            
            # íŠ¹ì„± ì¶”ì¶œ ë° ìƒíƒœ íŠ¹ì„±í™”
            features_dict = self.extract_features(df)
            characteristics = self.characterize_market_state(features_dict)
            
            # ìƒíƒœ ê°ì²´ ì—…ë°ì´íŠ¸ ë˜ëŠ” ìƒì„±
            if current_state_id in self.market_states:
                state = self.market_states[current_state_id]
                state.update(features_dict, characteristics)
            else:
                state = MarketState(current_state_id, features_dict, characteristics)
                self.market_states[current_state_id] = state
                logger.info(f"ìƒˆ ì‹œì¥ ìƒíƒœ ê°ì§€: {state}")
            
            # ìƒíƒœ ê¸°ë¡
            self.state_history.append(current_state_id)
            self.current_state = state
            
            # ëª¨ë¸ ì €ì¥
            self._save_model()
            
            return state
            
        except Exception as e:
            logger.error(f"HMM ìƒíƒœ ê°ì§€ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            logger.info("í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´ ì‹¤í–‰")
            return self.detect_state_clustering(df)
    
    def detect_state_cusum(self, df):
        """CUSUM ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ì‹œì¥ ì²´ì œ ë³€í™” ê°ì§€"""
        if df is None or len(df) < 10:
            logger.error("CUSUMì„ ìœ„í•œ ë°ì´í„° ë¶€ì¡±")
            return None
            
        # ê°ì‹œí•  ì‹œê³„ì—´ (ì¢…ê°€ ë˜ëŠ” ë‹¤ë¥¸ ì§€í‘œ)
        target_series = df['close']
        current_value = target_series.iloc[-1]
        
        # ê¸°ì¤€ê°’ ì´ˆê¸°í™” (ì²« ì‹¤í–‰ ì‹œ)
        if self.cusum_baseline is None:
            self.cusum_baseline = target_series.iloc[-5:].mean()  # ìµœê·¼ 5ê°œ í‰ê· 
            self.cusum_pos = 0
            self.cusum_neg = 0
            logger.info(f"CUSUM ê¸°ì¤€ê°’ ì´ˆê¸°í™”: {self.cusum_baseline:.2f}")
        
        # í‘œì¤€í¸ì°¨ ê³„ì‚°
        std_dev = target_series.pct_change().std()
        
        # í˜„ì¬ê°’ê³¼ ê¸°ì¤€ê°’ì˜ ì°¨ì´ ê³„ì‚°
        diff = current_value / self.cusum_baseline - 1  # ìˆ˜ìµë¥ ë¡œ ê³„ì‚°
        
        # CUSUM ì—…ë°ì´íŠ¸
        self.cusum_pos = max(0, self.cusum_pos + diff)
        self.cusum_neg = max(0, self.cusum_neg - diff)
        
        # ë³€í™” ê°ì§€ ì—¬ë¶€ í™•ì¸
        state_changed = False
        threshold = self.cusum_threshold * std_dev
        
        if self.cusum_pos > threshold:
            logger.info(f"CUSUM: ìƒìŠ¹ ì¶”ì„¸ ë³€í™” ê°ì§€ (ëˆ„ì ê°’: {self.cusum_pos:.4f})")
            self.cusum_baseline = current_value  # ê¸°ì¤€ê°’ ì—…ë°ì´íŠ¸
            self.cusum_pos = 0
            self.cusum_neg = 0
            state_changed = True
            
        elif self.cusum_neg > threshold:
            logger.info(f"CUSUM: í•˜ë½ ì¶”ì„¸ ë³€í™” ê°ì§€ (ëˆ„ì ê°’: {self.cusum_neg:.4f})")
            self.cusum_baseline = current_value  # ê¸°ì¤€ê°’ ì—…ë°ì´íŠ¸
            self.cusum_pos = 0
            self.cusum_neg = 0
            state_changed = True
        
        # ìƒíƒœ ë³€í™”ê°€ ê°ì§€ë˜ë©´ ìƒˆ ìƒíƒœ ìƒì„±
        if state_changed:
            # ìƒíƒœ ID ìƒì„± (í˜„ì¬ ì‹œê°„ ê¸°ë°˜)
            state_id = datetime.now().strftime("%Y%m%d%H%M")
            
            # íŠ¹ì„± ì¶”ì¶œ ë° ìƒíƒœ íŠ¹ì„±í™”
            features = self.extract_features(df)
            characteristics = self.characterize_market_state(features)
            
            # ìƒˆ ìƒíƒœ ê°ì²´ ìƒì„±
            state = MarketState(state_id, features, characteristics)
            self.market_states[state_id] = state
            
            # ìƒíƒœ ê¸°ë¡
            self.state_history.append(state_id)
            self.current_state = state
            
            logger.info(f"ìƒˆ ì‹œì¥ ìƒíƒœ ê°ì§€: {state}")
            return state
        
        # ë³€í™”ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ìƒíƒœ ìœ ì§€
        if not self.current_state:
            # ì´ˆê¸° ìƒíƒœ ìƒì„±
            state_id = datetime.now().strftime("%Y%m%d%H%M")
            features = self.extract_features(df)
            characteristics = self.characterize_market_state(features)
            self.current_state = MarketState(state_id, features, characteristics)
            self.market_states[state_id] = self.current_state
            self.state_history.append(state_id)
            
        return self.current_state
    
    def detect_current_state(self):
        """í˜„ì¬ ì‹œì¥ ìƒíƒœ ê°ì§€ (ì•ˆì „í•œ fallback í¬í•¨)"""
        # ì´ì „ ìƒíƒœ ì €ì¥
        if self.current_state:
            self.previous_state_id = self.current_state.state_id
        
        # ë°ì´í„° ìˆ˜ì§‘
        df = self.collect_data()
        
        if df is None or len(df) < 10:
            logger.warning("ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ê¸°ë³¸ ìƒíƒœ ì‚¬ìš©")
            return self._create_default_state()
        
        # ê°ì§€ ë°©ë²•ì— ë”°ë¼ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© (ì•ˆì „í•œ ìˆœì„œ)
        new_state = None
        
        try:
            if self.detection_method == 'clustering':
                new_state = self.detect_state_clustering(df)
            elif self.detection_method == 'hmm':
                new_state = self.detect_state_hmm(df)
            elif self.detection_method == 'cusum':
                new_state = self.detect_state_cusum(df)
            else:
                logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê°ì§€ ë°©ë²•: {self.detection_method}")
                new_state = self.detect_state_clustering(df)  # ê¸°ë³¸ê°’ìœ¼ë¡œ clustering ì‚¬ìš©
                
        except Exception as e:
            logger.error(f"ìƒíƒœ ê°ì§€ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            logger.info("ê¸°ë³¸ í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´")
            try:
                new_state = self.detect_state_clustering(df)
            except Exception as e2:
                logger.error(f"í´ëŸ¬ìŠ¤í„°ë§ë„ ì‹¤íŒ¨: {e2}")
                new_state = self._create_default_state()
        
        # ìµœì¢… ì•ˆì „ì¥ì¹˜
        if new_state is None:
            logger.warning("ëª¨ë“  ìƒíƒœ ê°ì§€ ë°©ë²• ì‹¤íŒ¨, ê¸°ë³¸ ìƒíƒœ ì‚¬ìš©")
            new_state = self._create_default_state()
        
        # ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ previous_state_id ì—…ë°ì´íŠ¸ (ìˆ˜ì •)
        if new_state and self.current_state and new_state.state_id != self.current_state.state_id:
            self.previous_state_id = self.current_state.state_id
            logger.info(f"{self.ticker} ìƒíƒœ ë³€ê²½: {self.previous_state_id} â†’ {new_state.state_id}")
        
        return new_state
    
    def get_optimal_strategy(self, state_id=None):
        """íŠ¹ì • ìƒíƒœì— ìµœì í™”ëœ ì „ëµ ë°˜í™˜"""
        if state_id is None:
            if self.current_state is None:
                return None
            state_id = self.current_state.state_id
            
        if state_id not in self.market_states:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ ID: {state_id}")
            return None
            
        state = self.market_states[state_id]
        
        # ìµœì  ì „ëµì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ë°˜í™˜
        if state.optimal_strategy:
            return state.optimal_strategy
            
        # ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ìƒíƒœ íŠ¹ì„± ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ 
        characteristics = state.characteristics
        
        if not characteristics:
            return None
            
        strategy_info = {}
        
        # ì¶”ì„¸ ê¸°ë°˜ ì „ëµ ì„ íƒ
        if 'trend' in characteristics:
            if characteristics['trend'] in ["ê°•í•œ ìƒìŠ¹", "ì•½í•œ ìƒìŠ¹"]:
                strategy_info['type'] = 'trend_following'
                strategy_info['params'] = {
                    'weight_ma_cross': 1.5,
                    'weight_rsi': 0.7,
                    'buy_threshold': 0.3
                }
            elif characteristics['trend'] in ["ê°•í•œ í•˜ë½", "ì•½í•œ í•˜ë½"]:
                strategy_info['type'] = 'counter_trend'
                strategy_info['params'] = {
                    'weight_rsi': 1.5,
                    'weight_bb': 1.2,
                    'buy_threshold': 0.7
                }
        
        # ë³€ë™ì„± ê¸°ë°˜ ì „ëµ ì¡°ì •
        if 'volatility' in characteristics:
            if characteristics['volatility'] in ["ë§¤ìš° ë†’ìŒ", "ë†’ìŒ"]:
                if 'params' not in strategy_info:
                    strategy_info['params'] = {}
                strategy_info['params']['stop_loss'] = 0.04  # ë³€ë™ì„± ë†’ì„ ë•Œ ì†ì ˆ íƒ€ì´íŠ¸í•˜ê²Œ
                strategy_info['params']['take_profit'] = 0.08  # ë³€ë™ì„± ë†’ì„ ë•Œ ìµì ˆ ì ê·¹ì ìœ¼ë¡œ
            elif characteristics['volatility'] == "ë‚®ìŒ":
                if 'params' not in strategy_info:
                    strategy_info['params'] = {}
                strategy_info['params']['stop_loss'] = 0.07  # ë³€ë™ì„± ë‚®ì„ ë•Œ ì†ì ˆ ì—¬ìœ ìˆê²Œ
                strategy_info['params']['take_profit'] = 0.12  # ë³€ë™ì„± ë‚®ì„ ë•Œ ìµì ˆ ì—¬ìœ ìˆê²Œ
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.optimal_strategy = strategy_info
        
        return strategy_info
    
    def update_state_performance(self, state_id, strategy_name, performance):
        """ìƒíƒœë³„ ì „ëµ ì„±ëŠ¥ ì—…ë°ì´íŠ¸"""
        if state_id not in self.market_states:
            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ ID: {state_id}")
            return False
            
        # ìƒíƒœ-ì „ëµ ì„±ëŠ¥ ê¸°ë¡
        if state_id not in self.state_metrics:
            self.state_metrics[state_id] = {}
            
        if strategy_name not in self.state_metrics[state_id]:
            self.state_metrics[state_id][strategy_name] = []
            
        # ì„±ëŠ¥ ì¶”ê°€
        self.state_metrics[state_id][strategy_name].append(performance)
        
        # ì„±ëŠ¥ì— ë”°ë¼ ìµœì  ì „ëµ ì—…ë°ì´íŠ¸
        self._update_optimal_strategy(state_id)
        
        return True
    
    def _update_optimal_strategy(self, state_id):
        """ì„±ëŠ¥ ê¸°ë°˜ìœ¼ë¡œ ìµœì  ì „ëµ ì—…ë°ì´íŠ¸"""
        if state_id not in self.state_metrics:
            return
        
        best_strategy = None
        best_performance = -float('inf')
        
        # ê° ì „ëµë³„ í‰ê·  ì„±ëŠ¥ ê³„ì‚°
        for strategy_name, performances in self.state_metrics[state_id].items():
            if not performances:
                continue
                
            avg_performance = sum(performances) / len(performances)
            
            if avg_performance > best_performance:
                best_performance = avg_performance
                best_strategy = strategy_name
        
        # ìµœì  ì „ëµ ì—…ë°ì´íŠ¸
        if best_strategy and state_id in self.market_states:
            self.market_states[state_id].optimal_strategy = {
                'type': best_strategy,
                'avg_performance': best_performance
            }
            logger.info(f"ìƒíƒœ {state_id}ì˜ ìµœì  ì „ëµ ì—…ë°ì´íŠ¸: {best_strategy} (ì„±ëŠ¥: {best_performance:.2f})")
    
    def _save_model(self):
        """í˜„ì¬ ëª¨ë¸ ë° ìƒíƒœ ì •ë³´ ì €ì¥"""
        try:
            # ì €ì¥ íŒŒì¼ëª… ìƒì„±
            filename = f"{self.ticker}_{self.detection_method}_{self.n_states}.joblib"
            filepath = os.path.join(self.save_dir, filename)
            
            # ì €ì¥ ë°ì´í„° ì¤€ë¹„
            save_data = {
                'model': self.model,
                'scaler': self.scaler,
                'detection_method': self.detection_method,
                'n_states': self.n_states,
                'market_states': self.market_states,
                'state_metrics': self.state_metrics,
                'saved_at': datetime.now()
            }
            
            # ì €ì¥
            joblib.dump(save_data, filepath)
            logger.debug(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            
            # ìƒíƒœ ì •ë³´ JSONìœ¼ë¡œë„ ì €ì¥ (ì½ê¸° ì‰½ê²Œ)
            json_path = os.path.join(self.save_dir, f"{self.ticker}_states.json")
            
            states_json = {}
            for state_id, state in self.market_states.items():
                states_json[state_id] = {
                    'characteristics': state.characteristics,
                    'occurrences': state.occurrences,
                    'last_seen': state.last_seen.strftime("%Y-%m-%d %H:%M:%S"),
                    'optimal_strategy': state.optimal_strategy
                }
                
            with open(json_path, 'w') as f:
                json.dump(states_json, f, indent=2, default=str)
            
            return True
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def start_auto_detection(self):
        """ìë™ ìƒíƒœ ê°ì§€ ì‹œì‘"""
        if self.running:
            return
            
        self.running = True
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        detection_thread = Thread(target=self._detection_loop)
        detection_thread.daemon = True
        detection_thread.start()
        
        logger.info("ì‹œì¥ ìƒíƒœ ê°ì§€ê¸° ì‹œì‘ë¨")
    
    def _detection_loop(self):
        """ìƒíƒœ ê°ì§€ ë£¨í”„"""
        while self.running:
            try:
                # í˜„ì¬ ìƒíƒœ ê°ì§€
                current_state = self.detect_current_state()
                
                if current_state:
                    logger.info(f"í˜„ì¬ ì‹œì¥ ìƒíƒœ: {current_state}")
                
                # ì¼ì • ì‹œê°„ ëŒ€ê¸°
                time.sleep(self.update_interval)
                
            except Exception as e:
                logger.error(f"ìƒíƒœ ê°ì§€ ì˜¤ë¥˜: {e}")
                time.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ í›„ ì¬ì‹œë„
    
    def stop_auto_detection(self):
        """ìë™ ìƒíƒœ ê°ì§€ ì¤‘ì§€"""
        self.running = False
        logger.info("ì‹œì¥ ìƒíƒœ ê°ì§€ê¸° ì¤‘ì§€ë¨")
    
    def get_current_state_info(self):
        """í˜„ì¬ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        if self.current_state is None:
            return None
            
        return self.current_state.get_state_summary()

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    detector = MarketStateDetector(ticker="KRW-BTC", detection_method='clustering', n_states=5)
    
    # ìë™ ê°ì§€ ì‹œì‘
    detector.start_auto_detection()
    
    try:
        # ë©”ì¸ ìŠ¤ë ˆë“œëŠ” ë‹¤ë¥¸ ì‘ì—… ìˆ˜í–‰ ê°€ëŠ¥
        while True:
            time.sleep(10)
            if detector.current_state:
                print(f"í˜„ì¬ ìƒíƒœ: {detector.current_state}")
                print(f"ìµœì  ì „ëµ: {detector.get_optimal_strategy()}")
                print("------------------------")
    
    except KeyboardInterrupt:
        detector.stop_auto_detection()
        print("í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")